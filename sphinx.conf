## Конфигурационный файл Sphinx-а для индексации LiveStreet
 
#######################
#
# Описываем индексы
#
#######################
 
# Источник-родитель для всех остальных источников. Здесь указываются параметры доступа
# к базе данных сайта
source lsParentSource
{
        type            = mysql
        sql_host        = 127.0.0.5
        sql_user        = root
        sql_pass        = 
        sql_db          = social
        sql_port        = 3306
        # Для ускорения работы прописываем путь до MySQL-го UNIX-сокета (чтобы
        # операции с БД происходили не через TCP/IP стек сервера)
        sql_sock        = /var/run/mysqld/mysqld.sock
   
       
        mysql_connect_flags     = 32 # 32- включение сжатие при обмене данными с БД
   
        # Включам нужную кодировку соединения и выключаем кеш запросов
        sql_query_pre                   = SET NAMES utf8
        sql_query_pre                   = SET SESSION query_cache_type=OFF    
}
 
# Источник топиков
source topicsSource : lsParentSource
{
        # запрос на получения данных топиков
        sql_query               = \
                SELECT t_fast.topic_id, t_fast.topic_title, UNIX_TIMESTAMP(t_fast.topic_date_add) as topic_date_add, \
                tc.topic_text, t_fast.topic_publish \
                FROM prefix_topic as t_fast, prefix_topic_content AS tc \
                WHERE t_fast.topic_id=tc.topic_id AND t_fast.topic_id>=$start AND t_fast.topic_id<=$end
 
        # запрос для дробления получения топиков на неколько итераций
        sql_query_range         = SELECT MIN(topic_id),MAX(topic_id) FROM prefix_topic
       
        # сколько получать объектов за итерацию
        sql_range_step          = 1000
 
       
        # Указываем булевый атрибут критерия "топик опубликован". Для возможности указания этого критерия при поиске
        sql_attr_uint = topic_publish
 
        # Атрибут даты добавления, типа "время"
        sql_attr_timestamp      = topic_date_add
 
        # мульти-аттрибут "теги топика"
        sql_attr_multi  = uint tag from query; SELECT topic_id, topic_tag_id FROM prefix_topic_tag
 
        sql_ranged_throttle     = 0
}
 
# Источник комментариев
source commentsSource : lsParentSource
{
        sql_query               = \
                        SELECT comment_id, comment_text, UNIX_TIMESTAMP(comment_date) as comment_date, comment_delete \
                        FROM prefix_comment \
                        WHERE target_type='topic' AND comment_id>=$start AND comment_id<=$end AND comment_publish=1
 
        sql_query_range         = SELECT MIN(comment_id),MAX(comment_id) FROM prefix_comment
        sql_range_step          = 1000
 
        sql_attr_uint = comment_delete
        sql_attr_timestamp      = comment_date
}

# Источник пользователей
source usersSource : lsParentSource
{
        # запрос на получения данных пользователей
        sql_query               = \
                SELECT user_id, user_login, user_profile_name, user_activate, UNIX_TIMESTAMP(user_date_register) as user_date_register, user_profile_about \
                FROM prefix_user \
                WHERE user_id>=$start AND user_id<=$end
 
        # запрос для дробления получения пользователей на неколько итераций
        sql_query_range         = SELECT MIN(user_id),MAX(user_id) FROM prefix_user
       
        # сколько получать объектов за итерацию
        sql_range_step          = 1000
 
       
        # Указываем булевый атрибут критерия "пользователь активирован". Для возможности указания этого критерия при поиске
        sql_attr_uint = user_activate
 
        # Атрибут даты добавления, типа "время"
        sql_attr_timestamp      = user_date_register
 
        sql_ranged_throttle     = 0
}

source blogsSource : lsParentSource
{
        # запрос на получения данных блогов
        sql_query               = \
                SELECT blog_id, blog_type, blog_title, UNIX_TIMESTAMP(blog_date_add) as blog_date_add, blog_description \
                FROM prefix_blog \
                WHERE blog_type='open' AND blog_id>=$start AND blog_id<=$end
 
        # запрос для дробления получения блогов на неколько итераций
        sql_query_range         = SELECT MIN(blog_id),MAX(blog_id) FROM prefix_blog
       
        # сколько получать объектов за итерацию
        sql_range_step          = 1000
 
       
        # Указываем атрибут критерия "блог открыт". Для возможности указания этого критерия при поиске
		# Оставлено для поиска по различным типам блогов (открытый закрытый личный инвайтный)
        # sql_field_string= blog_type
 
        # Атрибут даты добавления, типа "время"
        sql_attr_timestamp      = blog_date_add
 
        sql_ranged_throttle     = 0
}


#######################
#
# Описываем индексы
#
#######################
 
index topicsIndex
{
        # Источник, который будет хранить данный индекса
        source                  = topicsSource
        path                    = topicIndex
 
        # Тип хранения аттрибутов
        docinfo                 = extern
 
        mlock                   = 0
 
        # Используемые морфологические движки
        morphology = stem_enru
 
        # Кодировака данных из источника    
        charset_type            = utf-8
 
 
        # Из данных источника HTML-код нужно вырезать
        html_strip                              = 1
        html_remove_elements = style, script, code
}
 
# Индекс комментариев
index commentsIndex
{
        source                  = commentsSource
        path                    = commentsIndex
 
        docinfo                 = extern
 
        mlock                   = 0
 
        morphology = stem_enru
 
        charset_type            = utf-8
        
        # Из данных источника HTML-код нужно вырезать
        html_strip                              = 1
        html_remove_elements = style, script, code
}

index usersIndex
{
        # Источник, который будет хранить данный индекса
        source                  = usersSource
        path                    = userIndex
 
        # Тип хранения аттрибутов
        docinfo                 = extern
 
        mlock                   = 0
 
        # Используемые морфологические движки
        morphology = stem_enru
 
        # Кодировака данных из источника    
        charset_type            = utf-8
 
 
        # Из данных источника HTML-код нужно вырезать
        html_strip                              = 1
        html_remove_elements = style, script, code
}

index blogsIndex
{
        # Источник, который будет хранить данный индекса
        source                  = blogsSource
        path                    = blogIndex
 
        # Тип хранения аттрибутов
        docinfo                 = extern
 
        mlock                   = 0
 
        # Используемые морфологические движки
        morphology = stem_enru
 
        # Кодировака данных из источника    
        charset_type            = utf-8
 
 
        # Из данных источника HTML-код нужно вырезать
        html_strip                              = 1
        html_remove_elements = style, script, code
}



#######################
#
# Настройки индексатора
#
#######################
 
 
indexer
{
        # Лимит памяти, который может использавать демон-индексатор
        mem_limit                       = 128M
}
 
#######################
#
# Настройка демона-поисковика
#
#######################
 
searchd
{
        # Адрес, на котором будет прослушиваться порт
        listen                         = 127.0.0.1
 
 
        # Ну и собственно номер порта демона searchd
        port                            = 3312
 
        # Лог-файл демона
        log                                     = searchd.log
 
        # Лог поисковых запросов. Если закомментировать,то логировать поисковые строки не будет
        query_log                       = query.log
 
        # Время в секундах, которое ждет демон при обмене данными с клиентом. По исчерпании происходит разрыв коннекта
        read_timeout            = 5
 
        # Максимальное количество одновременно-обрабатываемых запросов. 0 означает дофига, а точнее без ограничения
        max_children            = 100
 
        # Файл, в который сохраняется PID-процесса при запуске
        pid_file                        = searchd.pid
}